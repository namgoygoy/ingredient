"""
ë²¡í„° ìŠ¤í† ì–´ ëª¨ë“ˆ
ChromaDB ë²¡í„° ìŠ¤í† ì–´ ê´€ë¦¬
"""

import logging
from typing import List, Dict

from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import SentenceTransformerEmbeddings

logger = logging.getLogger(__name__)


class VectorStore:
    """
    ChromaDB ë²¡í„° ìŠ¤í† ì–´ ê´€ë¦¬ í´ë˜ìŠ¤
    
    ì„±ë¶„ ì •ë³´ë¥¼ ì„ë² ë”©í•˜ì—¬ ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥í•˜ê³  ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, ingredients_data: List[Dict], persist_directory: str = "./chroma_db_ingredients"):
        """
        ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
        
        Args:
            ingredients_data: ì„±ë¶„ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            persist_directory: ChromaDB ë²¡í„° ìŠ¤í† ì–´ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        self.ingredients_data = ingredients_data
        self.persist_directory = persist_directory
        self.text_splitter = None
        self.embeddings = None
        self.vectorstore = None
        self.retriever = None
        self._initialize()
    
    def _initialize(self):
        """
        ë²¡í„° ìŠ¤í† ì–´ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        
        ì´ˆê¸°í™” ê³¼ì •:
        1. LangChain ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        2. ë¬¸ì„œ ìƒì„± ë° ì²­í¬ ë¶„í• 
        3. ChromaDBì— ì €ì¥
        4. Retriever ìƒì„±
        """
        logger.info("ğŸ”§ LangChain ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì¤‘...")
        
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000, chunk_overlap=200
        )
        
        self.embeddings = SentenceTransformerEmbeddings(
            model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        )
        
        logger.info("ğŸ—„ï¸ ChromaDB ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì¤‘...")
        self._create_vectorstore()
        logger.info("âœ… LangChain ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _create_vectorstore(self):
        """
        ChromaDB ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        ê° ì„±ë¶„ ì •ë³´ë¥¼ Documentë¡œ ë³€í™˜í•˜ì—¬ ë²¡í„° ìŠ¤í† ì–´ì— ì €ì¥í•©ë‹ˆë‹¤.
        """
        documents = []
        for item in self.ingredients_data:
            kor_name = item.get('kor_name', '')
            eng_name = item.get('eng_name', '')
            description = item.get('description', '')
            purpose = item.get('purpose', [])
            good_for = item.get('good_for', [])
            bad_for = item.get('bad_for', [])
            
            content_parts = []
            if kor_name:
                content_parts.append(f"í•œêµ­ì–´ ì„±ë¶„ëª…: {kor_name}")
            if eng_name:
                content_parts.append(f"ì˜ì–´ ì„±ë¶„ëª…: {eng_name}")
            if description:
                content_parts.append(f"ì„¤ëª…: {description[:500]}")
            if purpose:
                content_parts.append(f"ëª©ì : {', '.join(purpose) if isinstance(purpose, list) else purpose}")
            if good_for:
                content_parts.append(f"ê¶Œì¥ í”¼ë¶€ íƒ€ì…: {', '.join(good_for) if isinstance(good_for, list) else good_for}")
            if bad_for:
                content_parts.append(f"ì£¼ì˜ í”¼ë¶€ íƒ€ì…: {', '.join(bad_for) if isinstance(bad_for, list) else bad_for}")
            
            content = "\n".join(content_parts)
            
            doc = Document(
                page_content=content,
                metadata={
                    "ingredient_kor": kor_name,
                    "ingredient_eng": eng_name,
                    "description": (description[:200] + "..." if description and len(description) > 200 else description) or '',
                    "purpose": ', '.join(purpose) if isinstance(purpose, list) else (purpose or ''),
                    "good_for": ', '.join(good_for) if isinstance(good_for, list) else (good_for or ''),
                    "bad_for": ', '.join(bad_for) if isinstance(bad_for, list) else (bad_for or '')
                }
            )
            documents.append(doc)
        
        split_docs = self.text_splitter.split_documents(documents)
        logger.info(f"ğŸ“„ {len(documents)}ê°œ ë¬¸ì„œë¥¼ {len(split_docs)}ê°œ ì²­í¬ë¡œ ë¶„í• ")
        
        self.vectorstore = Chroma.from_documents(
            documents=split_docs,
            embedding=self.embeddings,
            persist_directory=self.persist_directory
        )
        
        self.retriever = self.vectorstore.as_retriever(search_kwargs={"k": 3})
        logger.info("âœ… ChromaDB ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ")
    
    def search(self, query: str, top_k: int = 3) -> List[Document]:
        """
        ë²¡í„° ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            top_k: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ê°œìˆ˜
        
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ Document ë¦¬ìŠ¤íŠ¸
        """
        if self.retriever is None:
            return []
        
        # top_k ë™ì  ë³€ê²½
        self.retriever.search_kwargs["k"] = top_k
        return self.retriever.invoke(query)

